[{"path":"https://leesulab.github.io/arcMS/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2023 arcMS authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://leesulab.github.io/arcMS/articles/api-configuration.html","id":"unifi-api-configuration","dir":"Articles","previous_headings":"","what":"UNIFI API configuration","title":"UNIFI API configuration","text":"UNIFI API must configured properly arcMS connect correctly. installation, configuration connection parameters depend version UNIFI running. essentially configuration using Proteowizard msconvert software conversion.","code":""},{"path":"https://leesulab.github.io/arcMS/articles/api-configuration.html","id":"with-unifi","dir":"Articles","previous_headings":"UNIFI API configuration","what":"With UNIFI","title":"UNIFI API configuration","text":"Details Waters UNIFI API installation configuration can found https://www.waters.com/webassets/cms/support/docs/715005443rc.pdf","code":""},{"path":"https://leesulab.github.io/arcMS/articles/api-configuration.html","id":"installation","dir":"Articles","previous_headings":"UNIFI API configuration > With UNIFI","what":"Installation","title":"UNIFI API configuration","text":"UNIFI Web API directly installed UNIFI Workstation, must installed installation DVD drive folder installation files copied, UNIFIWebAPISetup.exe installer.","code":""},{"path":"https://leesulab.github.io/arcMS/articles/api-configuration.html","id":"configuration","dir":"Articles","previous_headings":"UNIFI API configuration > With UNIFI","what":"Configuration","title":"UNIFI API configuration","text":"Applications used Web API must registered UNIFI Client Authorization Application. can accessed UNIFI Administration page, clicking “External Application Security Configuration”. open browser page connect Waters UNIFI Identity Server (URL localname:50333/identity/admin#/). Users must connect (Login button) credentials (typically administrator/administrator). “new client” must created following configuration: must enabled edited following parameters: scope created automatically secret value must added manually.","code":""},{"path":"https://leesulab.github.io/arcMS/articles/api-configuration.html","id":"connection-parameters","dir":"Articles","previous_headings":"UNIFI API configuration > With UNIFI","what":"Connection parameters","title":"UNIFI API configuration","text":"URL used connection retrieval token following (changed installation): Default username password administrator administrator can pass values command necessary.","code":"con = create_connection_params(apihosturl = \"http://localhost:50034/unifi/v1\", identityurl = \"http://localhost:50333/identity/connect/token\")"},{"path":"https://leesulab.github.io/arcMS/articles/api-configuration.html","id":"with-waters_connect-unifi","dir":"Articles","previous_headings":"UNIFI API configuration","what":"With waters_connect UNIFI","title":"UNIFI API configuration","text":"Details waters_connect configuration can found video: https://videos.waters.com/detail/video/6342765707112/set--msconvert--waters_connect-3.0.0","code":""},{"path":"https://leesulab.github.io/arcMS/articles/api-configuration.html","id":"installation-1","dir":"Articles","previous_headings":"UNIFI API configuration > With waters_connect UNIFI","what":"Installation","title":"UNIFI API configuration","text":"waters_connect, API directly installed, additional installation step required.","code":""},{"path":"https://leesulab.github.io/arcMS/articles/api-configuration.html","id":"configuration-1","dir":"Articles","previous_headings":"UNIFI API configuration > With waters_connect UNIFI","what":"Configuration","title":"UNIFI API configuration","text":"Applications used Web API must registered ApplicationRegistrationTool.exe app (typically installed C:\\Program Files\\Waters\\waters_connect\\ApplicationRegistrationTool\\ folder). terminal application must executed admin rights (right click, Run administrator). Users must connect credentials (typically administrator/administrator). new client application can registered typing R, followed following configuration: Client scope automatically set webapi.","code":""},{"path":"https://leesulab.github.io/arcMS/articles/api-configuration.html","id":"connection-parameters-1","dir":"Articles","previous_headings":"UNIFI API configuration > With waters_connect UNIFI","what":"Connection parameters","title":"UNIFI API configuration","text":"URL used connection retrieval token following: Default username password administrator administrator can pass values command necessary.","code":"con = create_connection_params(apihosturl = \"https://localhost:48505/unifi/v1\", identityurl = \"https://localhost:48333/connect/token\")"},{"path":"https://leesulab.github.io/arcMS/articles/collect-save-functions.html","id":"functions-to-collect-and-save-data","dir":"Articles","previous_headings":"","what":"Functions to collect and save data","title":"Collect and Save functions","text":"collect_one_sample_data() function can used collect data API R object processing without saving disk. save_one_sample_data() function can used save R object Parquet file. convert_one_sample_data() just combination two functions .","code":"collected_data = collect_one_sample_data(sample_id = \"0134efbf-c75a-411b-842a-4f35e2b76347\") save_one_sample_data(collected_data)"},{"path":"https://leesulab.github.io/arcMS/articles/data-filtration-tutorial.html","id":"loading-data-in-memory","dir":"Articles","previous_headings":"","what":"Loading data in memory","title":"Queries and filtration of Parquet files - full tutorial","text":"arrow package, easy load file (example file can download: cal1_sample.parquet) R environment dataframe/data.table: columns file : Loading data really fast dataframe can quickly sorted/arranged/aggregated desired modern libraries data.table. example can quickly get Total Ion Chromatogram (filtering data keep low collision energy data - similar keep MS1 data keep MS2 data): still, loaded data example sample occupies ~1.9 Gb memory, whole sequence usually 10-30 samples (even using triplicate injections) can quickly fill available RAM computers.","code":"library(arrow) library(data.table) library(dplyr) library(duckdb) library(plotly) data = read_parquet(\"converted_file.parquet\") head(data) #> # A tibble: 6 × 7 #>        rt scanid mslevel    mz intensity   bin    dt #>     <dbl>  <int> <fct>   <dbl>     <dbl> <int> <dbl> #> 1 0.00740      1 1        556.         0    19  1.35 #> 2 0.00740      1 1        556.         5    19  1.35 #> 3 0.00740      1 1        556.         7    19  1.35 #> 4 0.00740      1 1        556.         0    19  1.35 #> 5 0.00740      1 1        556.         0    23  1.63 #> 6 0.00740      1 1        556.         1    23  1.63 datalow = data[mslevel == 1, ] TIC = datalow[, list(intensity = sum(intensity)), by=list(rt)] plot_ly(TIC,                  y=~intensity,                  x=~rt,                 type = 'scatter',                 mode = 'lines',                 line = list(color = 'rgba(0,0,0,1)', width = 1),                 line = list(shape = 'spline', smoothing = 1) )"},{"path":"https://leesulab.github.io/arcMS/articles/data-filtration-tutorial.html","id":"querying-data-with-arrow","dir":"Articles","previous_headings":"","what":"Querying data with Arrow","title":"Queries and filtration of Parquet files - full tutorial","text":"Arrow library can read parquet files without loading whole file memory… magic happened! {{< fa wand-magic-sparkles size=1.4xl >}} described vignette(\"open-files\"), parquet file can also read -disk R open_dataset() function: just created pointer Parquet file, loaded memory yet. Data can filtered, rearranged, sorted aggregated dplyr syntax, resulting data loaded RAM (collect() function): block collect low energy data arranged increasing scanid (identifier retention time scan). get overview columns available file, type content, use str(data_arrow) summary(data_arrow) can use glimpse(data_arrow) dplyr package: can also use summarise() function grouping column interest, example obtain values mslevel column quickly:","code":"data_arrow = open_dataset(\"converted_file.parquet\") fulldatalow = data_arrow |>    filter(mslevel == 1) |>    arrange(scanid) |>    collect() glimpse(data_arrow) #> FileSystemDataset with 1 Parquet file #> 57,980,927 rows x 7 columns #> $ rt               <double> 0.007404283, 0.007404283, 0.00740428… #> $ scanid            <int32> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, … #> $ mslevel <dictionary<...>> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, … #> $ mz               <double> 556.2536, 556.2566, 556.2596, 556.26… #> $ intensity        <double> 0, 5, 7, 0, 0, 1, 2, 0, 0, 3, 2, 0, … #> $ bin               <int32> 19, 19, 19, 19, 23, 23, 23, 23, 23, … #> $ dt               <double> 1.349, 1.349, 1.349, 1.349, 1.633, 1… #> Call `print()` for full schema details data_arrow |>    group_by(mslevel) |>   summarise() |>   collect() #> # A tibble: 2 × 1 #>   mslevel #>   <fct>   #> 1 1       #> 2 2"},{"path":[]},{"path":"https://leesulab.github.io/arcMS/articles/data-filtration-tutorial.html","id":"tic","dir":"Articles","previous_headings":"Chromatograms","what":"TIC","title":"Queries and filtration of Parquet files - full tutorial","text":"Obtaining TIC now just matter aggregating intensity values retention time: took around 1s resulting data 64 Kb!","code":"TIC = data_arrow |>   filter(mslevel == \"1\") |>   group_by(rt) |>    summarise(int = sum(intensity)) |>    collect() format(object.size(TIC), unit = 'auto') #> [1] \"64.8 Kb\""},{"path":"https://leesulab.github.io/arcMS/articles/data-filtration-tutorial.html","id":"bpi","dir":"Articles","previous_headings":"Chromatograms","what":"BPI","title":"Queries and filtration of Parquet files - full tutorial","text":"now want Base Peak Chromatogram (BPI) instead TIC, simply use max() function take peak maximum intensity retention time:","code":"BPI = data_arrow |>   filter(mslevel == \"1\") |>   arrange(rt) |>   group_by(rt) |>    summarise(intensity = max(intensity)) |>    collect() plot_ly(BPI,                  y=~intensity,                  x=~rt,                  type = 'scatter',                 mode = 'lines',                 line = list(color = 'rgba(0,0,0,1)', width = 1),                 line = list(shape = 'spline', smoothing = 1) )"},{"path":"https://leesulab.github.io/arcMS/articles/data-filtration-tutorial.html","id":"extracted-ion-chromatogram-eic","dir":"Articles","previous_headings":"Chromatograms","what":"Extracted Ion Chromatogram (EIC)","title":"Queries and filtration of Parquet files - full tutorial","text":"Now want keep data around selected m/z ratio obtain EIC (say around m/z ratio atrazine: 216.1016), can use filter function (choose tolerance m/z window):","code":"EIC = data_arrow |>   filter(mslevel == \"1\") |>   arrange(rt) |>   filter(mz > 216.0016 & mz < 216.2016) |>    group_by(rt, scanid) |>   summarise(intensity = sum(intensity)) |>   collect()  EIC = as.data.table(EIC) plot_ly(EIC,                  y=~intensity,                  x=~rt,                 type = 'scatter',                 mode = 'lines',                 line = list(color = 'rgba(0,0,0,1)', width = 1),                 line = list(shape = 'spline', smoothing = 1) )"},{"path":"https://leesulab.github.io/arcMS/articles/data-filtration-tutorial.html","id":"full-2d-plots","dir":"Articles","previous_headings":"","what":"Full 2D plots","title":"Queries and filtration of Parquet files - full tutorial","text":"Now, can handle data? example, want plot full 2D plot displaying m/z vs rt, rt vs dt/bin, m/z vs dt/bin? first approach simply aggregate data two groups choice, e.g. rt mz, get rid third parameter (dt bin): bit longer resulting object ~300 Mb, even removing zero intensity values, ~1 million lines rt mz values, way large obtain matrix can used plotting heatmap contour plot plotly. le’ts try apply data reduction binning close rt mz values obtain smaller matrix, directly list arrow commands mutate function: resulting object now just several Mbs, query takes ~30s 1 min depending value chosen binning mz rt values. Now DuckDB enters! database management system can query Arrow data directly SQL interface, without copy data. allows users make queries yet available Arrow dplyr syntax, can process complex data types efficiently. use DuckDB, one line needed dplyr pipeline! just need transfer data (zero-copy streaming) DuckDB system to_duckdb() function: now runs seconds… can prepare matrix 2D contour plot: data used 3D plot well, depicted miniature post. Zooming hovering plot give accurate masses just raw preview data due binning floor() function, make new query obtain accurate data specific rt mz ranges, without binning, e.g. around atrazine:","code":"rtmz = data_arrow |>   filter(mslevel == \"1\") |>   arrange(rt) |>   group_by(rt, mz) |>    summarise(intensity = sum(intensity)) |>    collect()  rtmz = as.data.table(rtmz) rtmz = rtmz[intensity != 0,] rtmz = rtmz[order(rtmz$mz),] rtmz = rtmz[order(rtmz$rt),] rtmzbinned = data_arrow |>   filter(mslevel == \"1\") |>   arrange(rt) |>   group_by(rt, mz) |>    summarise(sum_int = sum(intensity)) |>    mutate(rt_binned = floor(rt/0.1)*0.1) |>   mutate(mz_binned = floor(mz/1)*1) |>   group_by(rt_binned, mz_binned) |>   summarise(sum_int_binned = sum(sum_int)) |>    collect() library(duckdb)  rtmzbinned = data_arrow |>   to_duckdb() |>   filter(mslevel == \"1\") |>   mutate(rt_binned = floor(rt/0.1)*0.1) |>   mutate(mz_binned = floor(mz/1)*1) |>   group_by(rt_binned, mz_binned) |>   summarise(intensity = sum(intensity)) |>   collect()  rtmzbinned = as.data.table(rtmzbinned) rtmzbinned = setorderv(rtmzbinned, c(\"rt_binned\", \"mz_binned\")) spreaddt = rtmzbinned |> pivot_wider(names_from = rt_binned, values_from = intensity) spreaddt = spreaddt[order(spreaddt$mz_binned),] setnafill(spreaddt, fill = 0) spreadmatrix = as.matrix(spreaddt[,-1]) plot_ly(   x = as.numeric(colnames(spreaddt[,-1])),   y = spreaddt$mz_binned,   z = spreadmatrix,   type = \"heatmap\",   zmin = 0,   zmax = 100000 ) plot_ly(   x = as.numeric(colnames(spreaddt[,-1])),   y = spreaddt$mz,   z = spreadmatrix,   type = \"contour\",   zmin = 0,   zmax = 100000 )"},{"path":"https://leesulab.github.io/arcMS/articles/data-filtration-tutorial.html","id":"ms-spectra","dir":"Articles","previous_headings":"","what":"MS spectra","title":"Queries and filtration of Parquet files - full tutorial","text":"Plotting MS spectra straightforward point: ’s high energy spectrum (“MS2”) atrazine profile mode (knowing scanid numbers around corresponding retention time): Now want clean spectrum filtered thanks ion mobility, need know drift time molecule interest, always case. case drift time available, can filter based bin parameter corresponding mobility separation (1 200 bins rt). can thus plot IMS 2D trace given rt, list rts (selected scanid): bin value atrazine around 62. plot, also see molecule bin ~50 m/z ~174, probably -source fragment atrazine thus showing different drift time.","code":"scanids = c(1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160)  MS = data_arrow |>   filter(mslevel == \"1\") |>   filter(scanid %in% !!scanids) |>   group_by(mz) |>   summarise(intensity = sum(intensity)) |>   arrange(mz) |>   collect() plot_ly(data = MS,          x = ~mz,          y = ~intensity,          type=\"scatter\",         mode = \"line\") %>%     layout(            xaxis = list(title = \"m/z\"),            yaxis = list(title = \"Intensity\")) scanids = c(1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160)    IMStrace = data_arrow |>     to_duckdb() |>     filter(mslevel == \"1\") |>     filter(scanid %in% !!scanids) |>     group_by(bin, mz) |>     summarise(sum_int = sum(intensity)) |>     mutate(mz_binned = floor(mz/1)*1) |>     group_by(bin, mz_binned) |>     summarise(sum_int_binned = sum(sum_int)) |>      collect()  IMStrace = IMStrace[order(IMStrace$bin),] spreadIMS = IMStrace |> pivot_wider(names_from = bin, values_from = sum_int_binned) spreadIMS = spreadIMS[order(spreadIMS$mz_binned),] setnafill(spreadIMS, fill = 0) spreadmatrixIMS = as.matrix(spreadIMS[,-1]) plot_ly(   x = as.numeric(colnames(spreadIMS[,-1])),   y = spreadIMS$mz_binned,   z = spreadmatrixIMS,   type = \"heatmap\",   zmin = 0,   zmax = 100000 ) %>%     layout(            xaxis = list(title = \"bin\"),            yaxis = list(title = \"m/z\"))"},{"path":"https://leesulab.github.io/arcMS/articles/data-filtration-tutorial.html","id":"ms-spectrum-filtering","dir":"Articles","previous_headings":"MS spectra","what":"MS spectrum filtering","title":"Queries and filtration of Parquet files - full tutorial","text":"Now found bin values atrazine ~55 ~70, can use filter() function select values fo interest: quickly combined several scans (retention times) several bins corresponding atrazine, almost completely filtered molecule.","code":"scanids = c(1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160) binsarray = c(58, 59, 60, 61, 62, 63, 64, 65, 66)  MSf = data_arrow |>   filter(mslevel == \"1\") |>   filter(scanid %in% !!scanids) |>   filter(bin %in% binsarray) |>   group_by(mz) |>   summarise(intensity = sum(intensity)) |>   arrange(mz) |>   collect() plot_ly(data = MSf,          x = ~mz,          y = ~intensity,          type=\"scatter\",         mode = \"line\") %>%     layout(            xaxis = list(title = \"m/z\"),            yaxis = list(title = \"Intensity\"))"},{"path":"https://leesulab.github.io/arcMS/articles/data-filtration-tutorial.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Queries and filtration of Parquet files - full tutorial","text":"Apache Parquet file format, addition high compression light data files, can read directly Arrow library without loading data memory. interoperability Arrow, DuckDB dplyr makes data queries extremely fast easy write lines. Parquet, Arrow DuckDB cross-platform multi-language: can used R, Python Julia. Thanks possibilities, developed simple R Shiny application visualize HRMS data directly browser, without requiring workstations lots RAM.","code":""},{"path":"https://leesulab.github.io/arcMS/articles/get-ccs-values.html","id":"get-ccs-values","dir":"Articles","previous_headings":"","what":"Get CCS values","title":"Get CCS values","text":"HDMSE data (IMS), CCS values can retrieved UNIFI API. API call requires passing m/z values, charges retention times. Therefore, recommended use peaks present raw data avoid excessive requests unnecessary CCS calculations (e.g., fragments isotopes). conversion performed limited number detected peaks. Detected peak lists can obtained peak detection software algorithm. DEIMoS Python library can easily used MS data converted arcMS Parquet format. can perform peak detection obtain reduced list peaks CCS values can retrieved. conversion operation based drift time calibration HDMSe result. possible CCS calibration performed. convert bin index values CCS calibrated values, expressed angstrom squared. convert_bin_to_ccs() function can used follows: takes Arrow table object containing sample data input. table must include necessary columns: bin, mz, rt, metadata must contain id sample. function returns Arrow table additional ccs column.","code":"convert_bin_to_ccs(arrow_data)"},{"path":"https://leesulab.github.io/arcMS/articles/open-files.html","id":"how-to-open-converted-files","dir":"Articles","previous_headings":"","what":"How to open converted files?","title":"Open Parquet files","text":"Parquet files created arcMS can easily opened R Python. also functions included arcMS package recreate sample_dataset objects Parquet files. class object associated generic functions quickly get data, metadata simple plots like TIC.","code":""},{"path":"https://leesulab.github.io/arcMS/articles/open-files.html","id":"load-converted-parquet-files-in-r-without-arcms","dir":"Articles","previous_headings":"How to open converted files?","what":"1. Load converted Parquet files in R without arcMS","title":"Open Parquet files","text":"Files created arcMS Parquet format can opened R Arrow library. Data can loaded RAM following commands: Data can filtered quickly aggregated, e.g. obtain TIC plot:  save RAM, data can also manipulated directly -disk thanks Arrow library (open_dataset() function): Data can filtered, rearranged, sorted aggregated dplyr syntax, resulting data loaded RAM (collect() function):","code":"library(arrow) data = read_parquet(\"converted_file.parquet\") head(data) #> # A tibble: 6 × 7 #>        rt scanid mslevel    mz intensity   bin    dt #>     <dbl>  <int> <fct>   <dbl>     <dbl> <int> <dbl> #> 1 0.00740      1 1        556.         0    19  1.35 #> 2 0.00740      1 1        556.         5    19  1.35 #> 3 0.00740      1 1        556.         7    19  1.35 #> 4 0.00740      1 1        556.         0    19  1.35 #> 5 0.00740      1 1        556.         0    23  1.63 #> 6 0.00740      1 1        556.         1    23  1.63 library(data.table) data = as.data.table(data) datalow = data[mslevel == 1, ] TIC = datalow[, list(intensity = sum(intensity)), by=list(rt)] plot(TIC$rt, TIC$intensity, type = \"l\") data = open_dataset(\"converted_file.parquet\") library(dplyr)  TIC = data |>   filter(mslevel == \"1\") |>   arrange(rt) |>   group_by(rt) |>    summarise(int = sum(intensity)) |>    collect()"},{"path":"https://leesulab.github.io/arcMS/articles/open-files.html","id":"load-converted-parquet-files-in-python","dir":"Articles","previous_headings":"How to open converted files?","what":"2. Load converted Parquet files in Python","title":"Open Parquet files","text":"Parquet files can opened DataFrame Python pandas library: can also loaded Arrow object (ParquetDataset) pyarrow library:","code":"import pandas as pd data = pd.read_parquet(\"converted_file.parquet\") ms1 = data[data['mslevel'] == \"1\"] print(ms1) import pyarrow.parquet as pq data = pq.ParquetDataset(\"converted_file.parquet\")"},{"path":"https://leesulab.github.io/arcMS/articles/open-files.html","id":"load-converted-parquet-files-in-r-with-arcms","dir":"Articles","previous_headings":"How to open converted files?","what":"3. Load converted Parquet files in R with arcMS","title":"Open Parquet files","text":"methods retrieve main data Parquet file, metadata. functions must used retrieve metadata. simplify opening data metadata, functions available arcMS load Parquet file sample_dataset object, also allowing easy manipulation generic functions. Retrieve main data: Retrieve sample metadata: Retrieve spectrum metadata:","code":"library(arcMS) dataset = create_sample_dataset(\"converted_file.parquet\") data = get_sample_data(dataset) head(data) #> # A tibble: 6 × 7 #>        rt scanid mslevel    mz intensity   bin    dt #>     <dbl>  <int> <fct>   <dbl>     <dbl> <int> <dbl> #> 1 0.00740      1 1        556.         0    19  1.35 #> 2 0.00740      1 1        556.         5    19  1.35 #> 3 0.00740      1 1        556.         7    19  1.35 #> 4 0.00740      1 1        556.         0    19  1.35 #> 5 0.00740      1 1        556.         0    23  1.63 #> 6 0.00740      1 1        556.         1    23  1.63 sample_metadata = get_sample_metadata(dataset) str(sample_metadata) #> Classes 'data.table' and 'data.frame':   1 obs. of  45 variables: #>  $ id                                    : chr \"0134efbf-c75a-411b-842a-4f35e2b76347\" #>  $ name                                  : chr \"cal 1\" #>  $ description                           : chr \"NaN\" #>  $ sample.description                    : chr \"NaN\" #>  $ sample.originalSampleId               : chr \"NaN\" #>  $ sample.id                             : chr \"8c6f3993-a791-4396-a299-b4dee758a5e7\" #>  $ sample.gender                         : chr \"NaN\" #>  $ sample.name                           : chr \"cal 1\" #>  $ sample.assayConditions                : chr \"NaN\" #>  $ sample.bracketGroup                   : chr \"NaN\" #>  $ sample.dose                           : chr \"NaN\" #>  $ sample.dosingRoute                    : chr \"NaN\" #>  $ sample.day                            : chr \"NaN\" #>  $ sample.eCordId                        : chr \"NaN\" #>  $ sample.experimentalConcentration      : chr \"NaN\" #>  $ sample.groupId                        : chr \"NaN\" #>  $ sample.injectionId                    : chr \"NaN\" #>  $ sample.matrix                         : chr \"NaN\" #>  $ sample.solventDelay                   : chr \"NaN\" #>  $ sample.species                        : chr \"NaN\" #>  $ sample.studyId                        : chr \"NaN\" #>  $ sample.subjectId                      : chr \"NaN\" #>  $ sample.molForm                        : chr \"NaN\" #>  $ sample.preparation                    : chr \"NaN\" #>  $ sample.sampleType                     : chr \"Standard\" #>  $ sample.batchId                        : chr \"NaN\" #>  $ sample.studyName                      : chr \"NaN\" #>  $ sample.sampleLevel                    : chr \"Unspecified\" #>  $ sample.sampleWeight                   : num 1 #>  $ sample.dilution                       : num 1 #>  $ sample.replicateNumber                : int 1 #>  $ sample.wellPosition                   : chr \"1:A,7\" #>  $ sample.injectionVolume                : num 10 #>  $ sample.acquisitionRunTime             : num 34 #>  $ sample.acquisitionStartTime           : chr \"2021-11-17T16:14:36.1683419+01:00\" #>  $ sample.time                           : chr \"NaN\" #>  $ sample.processingOptions              : chr \"QuantitationStd\" #>  $ sample.processingFunction             : chr \"NaN\" #>  $ sample.processingSequenceNumber       : int 0 #>  $ components.odata.navigationLink       : chr \"http://localhost:50034/unifi/v1/sampleresults(0134efbf-c75a-411b-842a-4f35e2b76347)/components\" #>  $ spectra.odata.navigationLink          : chr \"http://localhost:50034/unifi/v1/sampleresults(0134efbf-c75a-411b-842a-4f35e2b76347)/spectra/mass.mse\" #>  $ spectrumInfos.odata.navigationLink    : chr \"http://localhost:50034/unifi/v1/sampleresults(0134efbf-c75a-411b-842a-4f35e2b76347)/spectrumInfos\" #>  $ chromatogramInfos.odata.navigationLink: chr \"http://localhost:50034/unifi/v1/sampleresults(0134efbf-c75a-411b-842a-4f35e2b76347)/chromatogramInfos\" #>  $ sampleName                            : chr \"cal 1_replicate_1\" #>  $ analysisName                          : chr \"20211117_NORMAN_2e EIL_semi-quanti_Parent-TP products-testsAPI\" #>  - attr(*, \".internal.selfref\")=<externalptr> spectrum_metadata = get_spectrum_metadata(dataset) str(spectrum_metadata) #> Classes 'data.table' and 'data.frame':   3 obs. of  32 variables: #>  $ id                                                      : chr  \"a8d5230c-aaa3-4f34-9a20-738ae8484612\" \"896256ff-aa7e-4e45-b76c-5f4fb6275fd3\" \"b83dffcc-5817-4ff6-b535-f2ec0869e5e3\" #>  $ name                                                    : chr  \"1: MS LockSpray Reference Data (546.2766-566.2766) 6V ESI+\" \"2: HD TOF MSe (50-1000) 6V ESI+\" \"3: HD TOF MSe (50-1000) 20-56V ESI+\" #>  $ isCentroidData                                          : logi  FALSE FALSE FALSE #>  $ isRetentionData                                         : logi  TRUE TRUE TRUE #>  $ isIonMobilityData                                       : logi  FALSE TRUE TRUE #>  $ hasCCSCalibration                                       : logi  FALSE TRUE TRUE #>  $ detectorType                                            : chr  \"MS\" \"MS\" \"MS\" #>  $ analyticalTechnique.X.odata.type                        : chr  \"#Waters.WebApi.Common.Models.MSTechnique\" \"#Waters.WebApi.Common.Models.MSTechnique\" \"#Waters.WebApi.Common.Models.MSTechnique\" #>  $ analyticalTechnique.hardwareName                        : chr  \"NaN\" \"NaN\" \"NaN\" #>  $ analyticalTechnique.scanningMethod                      : chr  \"MS\" \"MS\" \"MS\" #>  $ analyticalTechnique.massAnalyser                        : chr  \"QTOF\" \"QTOF\" \"QTOF\" #>  $ analyticalTechnique.ionisationMode                      : chr  \"+\" \"+\" \"+\" #>  $ analyticalTechnique.ionisationType                      : chr  \"ESI\" \"ESI\" \"ESI\" #>  $ analyticalTechnique.lowMass                             : num  546 50 50 #>  $ analyticalTechnique.highMass                            : num  566 1000 1000 #>  $ analyticalTechnique.adcGroup.acquisitionMode            : chr  \"ADC_PD\" \"ADC_PD\" \"ADC_PD\" #>  $ analyticalTechnique.adcGroup.acquisitionFrequency       : chr  \"NaN\" \"NaN\" \"NaN\" #>  $ analyticalTechnique.tofGroup.nominalResolution          : num  30000 30000 30000 #>  $ analyticalTechnique.tofGroup.mseLevel                   : chr  \"Unknown\" \"Low\" \"High\" #>  $ analyticalTechnique.tofGroup.pusherFrequency            : num  14085 14085 14085 #>  $ analyticalTechnique.quadGroup                           : chr  \"NaN\" \"NaN\" \"NaN\" #>  $ axisX.label                                             : chr  \"Observed mass\" \"Observed mass\" \"Observed mass\" #>  $ axisX.unit                                              : chr  \"m/z\" \"m/z\" \"m/z\" #>  $ axisX.lowerBound                                        : num  546 50 50 #>  $ axisX.upperBound                                        : num  566 1000 1000 #>  $ axisY.label                                             : chr  \"Intensity\" \"Intensity\" \"Intensity\" #>  $ axisY.unit                                              : chr  \"Counts\" \"Counts\" \"Counts\" #>  $ axisY.lowerBound                                        : chr  \"NaN\" \"NaN\" \"NaN\" #>  $ axisY.upperBound                                        : chr  \"NaN\" \"NaN\" \"NaN\" #>  $ analyticalTechnique.adcGroup.ionResponses.ionType       : chr  \"PEPTIDE\" \"PEPTIDE\" \"PEPTIDE\" #>  $ analyticalTechnique.adcGroup.ionResponses.charge        : int  1 1 1 #>  $ analyticalTechnique.adcGroup.ionResponses.averageIonArea: num  5.92 5.92 5.92 #>  - attr(*, \".internal.selfref\")=<externalptr>"},{"path":"https://leesulab.github.io/arcMS/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Julien Le Roux. Author, maintainer. Julien Sade. Author.","code":""},{"path":"https://leesulab.github.io/arcMS/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Le Roux J, Sade J (2024). arcMS: MS converter UNIFI Parquet HDF5 formats. R package version 1.1.1, https://leesulab.github.io/arcMS/, https://github.com/leesulab/arcMS/.","code":"@Manual{,   title = {arcMS: MS converter from UNIFI to Parquet and HDF5 formats},   author = {Julien {Le Roux} and Julien Sade},   year = {2024},   note = {R package version 1.1.1, https://leesulab.github.io/arcMS/},   url = {https://github.com/leesulab/arcMS/}, }"},{"path":"https://leesulab.github.io/arcMS/index.html","id":"id_-arcms","dir":"","previous_headings":"","what":"MS converter from UNIFI to Parquet and HDF5 formats","title":"MS converter from UNIFI to Parquet and HDF5 formats","text":"arcMS can convert (HD)MSE data acquired Waters UNIFI tabular format use R Python, small filesize saved disk. compatible data containing ion mobility (HDMSE) (MSE). Two output data file formats can obtained: Apache Parquet format minimal filesize fast access. HDF5 format, fast access larger filesize. arcMS stands accessible, rapid compact, also based french word arc, means bow, emphasize compatible Apache Arrow library. companion app (R/Shiny app) provided https://github.com/leesulab/arcms-dataviz fast visualization converted data (Parquet format) 2D plots, TIC, BPI EIC chromatograms… Also, check vignette(\"open-files\") details converted files can opened R Python.","code":""},{"path":"https://leesulab.github.io/arcMS/index.html","id":"arrow_down-installation","dir":"","previous_headings":"","what":"⬇️ Installation","title":"MS converter from UNIFI to Parquet and HDF5 formats","text":"can install arcMS R following command: use HDF5 format, rhdf5 package needs installed:","code":"install.packages(\"pak\") pak::pak(\"leesulab/arcMS\") pak::pak(\"rhdf5\")"},{"path":"https://leesulab.github.io/arcMS/index.html","id":"id_-usage","dir":"","previous_headings":"","what":"🚀 Usage","title":"MS converter from UNIFI to Parquet and HDF5 formats","text":"First load package: create connection parameters UNIFI API (retrieve token). See vignette(\"api-configuration\") know configure API register client app. arcMS R session run another computer UNIFI API installed, replace localhost IP address UNIFI API. Now connection parameters used access UNIFI folders. following function show list folders IDs (e.g. abe9c297-821e-4152-854a-17c73c9ff68c example ). folder ID, can access list Analysis items folder: Finally, Analysis ID, can get list samples (injections) acquired Analysis: get sample ID, can use download sample data, using future framework parallel processing: command get sample name (sample_name) parent analysis (analysis_name), create folder named analysis_name working directory save sample data name sample_name.parquet metadata name sample_name-metadata.json (metadata also saved parquet file). Analysis ID, can convert save samples chosen Analysis: use HDF5 format instead Parquet, format argument can used : save samples data metadata file.h5 file. functions available collect data API R object, save R object Parquet file (see vignette(\"collect-save-functions\")). CCS values can also retrieved addition bin index drift time values, see vignette(\"get-ccs-values\"). Parquet HDF5 files can opened easily R arrow rhdf5 packages. Parquet files contain low high energy spectra (HDMSe), HDF5 files contain low energy “ms1” dataset, high energy “ms2” dataset, metadata “metadata” dataset. fromJSON function jsonlite package import metadata json file (associated Parquet file) list dataframes.","code":"library(\"arcMS\") con = create_connection_params(apihosturl = \"http://localhost:50034/unifi/v1\", identityurl = \"http://localhost:50333/identity/connect/token\") con = create_connection_params(apihosturl = \"http://192.0.2.0:50034/unifi/v1\", identityurl = \"http://192.0.2.0:50333/identity/connect/token\") folders = folders_search() folders #>                                     id       name               path folderType #> 3 abe9c297-821e-4152-854a-17c73c9ff68c Christelle Company/Christelle    Project #> 4 abe7a0e6-99d2-4e57-a618-f4b085f48443 EMMANUELLE Company/EMMANUELLE    Project #>                               parentId #> 3 7c3a0fc7-3805-4c14-ab68-8da3e115702e #> 4 7c3a0fc7-3805-4c14-ab68-8da3e115702e ana = analysis_search(\"abe9c297-821e-4152-854a-17c73c9ff68c\") ana samples = get_samples_list(\"e236bf99-31cd-44ae-a4e7-74915697df65\") samples library(future) plan(multisession) convert_one_sample_data(sample_id = \"0134efbf-c75a-411b-842a-4f35e2b76347\") convert_all_samples_data(analysis_id = \"e236bf99-31cd-44ae-a4e7-74915697df65\") convert_one_sample_data(sample_id = \"0134efbf-c75a-411b-842a-4f35e2b76347\", format = \"hdf5\")  convert_all_samples_data(analysis_id = \"e236bf99-31cd-44ae-a4e7-74915697df65\", format = \"hdf5\") sampleparquet = arrow::read_parquet(\"sample.parquet\") metadataparquet = jsonlite::fromJSON(\"sample-metadata.json\")  samplems1hdf5 = rhdf5::h5read(\"sample.h5\", name = \"ms1\") samplems2hdf5 = rhdf5::h5read(\"sample.h5\", name = \"ms2\") samplemetadatahdf5 = rhdf5::h5read(\"sample.h5\", name = \"samplemetadata\") spectrummetadatahdf5 = rhdf5::h5read(\"sample.h5\", name = \"spectrummetadata\")"},{"path":"https://leesulab.github.io/arcMS/index.html","id":"id_-shiny-app","dir":"","previous_headings":"","what":"✨ Shiny App","title":"MS converter from UNIFI to Parquet and HDF5 formats","text":"Shiny application available use package easily. run app, just use following command (might need install additional packages):","code":"run_app()"},{"path":"https://leesulab.github.io/arcMS/reference/DecodeVarint32.html","id":null,"dir":"Reference","previous_headings":"","what":"DecodeVarint32 — DecodeVarint32","title":"DecodeVarint32 — DecodeVarint32","text":"function decode buffer data.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/DecodeVarint32.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"DecodeVarint32 — DecodeVarint32","text":"","code":"DecodeVarint32(buffer, pos)"},{"path":"https://leesulab.github.io/arcMS/reference/DecodeVarint32.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"DecodeVarint32 — DecodeVarint32","text":"buffer buffer data pos position beginning message","code":""},{"path":"https://leesulab.github.io/arcMS/reference/DecodeVarint32.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"DecodeVarint32 — DecodeVarint32","text":"Decoded message position","code":""},{"path":"https://leesulab.github.io/arcMS/reference/DecodeVarint32.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"DecodeVarint32 — DecodeVarint32","text":"Encoder - https://github.com/protocolbuffers/protobuf/blob/master/python/google/protobuf/internal/encoder.py Decoder - https://raw.githubusercontent.com/protocolbuffers/protobuf/master/python/google/protobuf/internal/decoder.py Author - Fred K. Gruber <fred@gnshealthcare.com>","code":""},{"path":"https://leesulab.github.io/arcMS/reference/add_drift_time.html","id":null,"dir":"Reference","previous_headings":"","what":"Add Drift Time to Unnested Spectral Data — add_drift_time","title":"Add Drift Time to Unnested Spectral Data — add_drift_time","text":"function takes unnested data table spectral data adds drift time","code":""},{"path":"https://leesulab.github.io/arcMS/reference/add_drift_time.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add Drift Time to Unnested Spectral Data — add_drift_time","text":"","code":"add_drift_time(connection_params, unnestdt, sample_id)"},{"path":"https://leesulab.github.io/arcMS/reference/add_drift_time.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add Drift Time to Unnested Spectral Data — add_drift_time","text":"connection_params Connection parameters UNIFI API - url token unnestdt unnested data table contains least columns 'bin'. sample_id sample ID used API call.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/add_drift_time.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add Drift Time to Unnested Spectral Data — add_drift_time","text":"unnested data table additional column 'dt' drift time.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/analysis_search.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve Analyses from UNIFI API — analysis_search","title":"Retrieve Analyses from UNIFI API — analysis_search","text":"function retrieves items information UNIFI API specified UNIFI folder using provided connection parameters. function filters returns analysis items based type.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/analysis_search.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve Analyses from UNIFI API — analysis_search","text":"","code":"analysis_search(folder_id, connection_params = NULL)"},{"path":"https://leesulab.github.io/arcMS/reference/analysis_search.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve Analyses from UNIFI API — analysis_search","text":"folder_id identifier folder items retrieved. connection_params Connection parameters UNIFI API, including API host URL access token.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/analysis_search.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve Analyses from UNIFI API — analysis_search","text":"data frame containing analysis item information UNIFI API,         unnecessary columns removed clarity. Example usage: con_params <- create_connection_params(api_host_url, api_token) analysis_items <- analysis_search(con_params, folder_id)","code":""},{"path":"https://leesulab.github.io/arcMS/reference/arcMS-package.html","id":null,"dir":"Reference","previous_headings":"","what":"UNIFI MS converter to Parquet and HDF5 formats — arcMS-package","title":"UNIFI MS converter to Parquet and HDF5 formats — arcMS-package","text":"Functions connect Waters UNIFI API convert data Parquet HDF5 format.","code":""},{"path":[]},{"path":"https://leesulab.github.io/arcMS/reference/arcMS-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"UNIFI MS converter to Parquet and HDF5 formats — arcMS-package","text":"Maintainer: Julien Le Roux julien.le-roux@u-pec.fr (ORCID) Authors: Julien Sade julien.sade@u-pec.fr","code":""},{"path":"https://leesulab.github.io/arcMS/reference/collect_one_sample_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Collect data from one sample — collect_one_sample_data","title":"Collect data from one sample — collect_one_sample_data","text":"function collects spectral data sample UNIFI Analysis. First, asynchronous queries performed sample. , data deserialized function deserialize_data(). S3 object containing spectral data adapted dataframe function outputlist_to_df().","code":""},{"path":"https://leesulab.github.io/arcMS/reference/collect_one_sample_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Collect data from one sample — collect_one_sample_data","text":"","code":"collect_one_sample_data(   sample_id,   connection_params = NULL,   num_spectras = NULL )"},{"path":"https://leesulab.github.io/arcMS/reference/collect_one_sample_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Collect data from one sample — collect_one_sample_data","text":"sample_id id sample collected connection_params OPTIONAL: Connection parameters object created create_connection_params function. provided, get_connection_params look object global environment num_spectras OPTIONAL Number spectras downloaded (OPTIONAL, whole sample data needed, e.g. testing purposes)","code":""},{"path":"https://leesulab.github.io/arcMS/reference/collect_one_sample_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Collect data from one sample — collect_one_sample_data","text":"sample_dataset object, containing sample data, sample metadata spectrum metadata datatables.","code":""},{"path":[]},{"path":"https://leesulab.github.io/arcMS/reference/connection_params-class.html","id":null,"dir":"Reference","previous_headings":"","what":"Class containing UNIFI API connection parameters — connection_params-class","title":"Class containing UNIFI API connection parameters — connection_params-class","text":"Contains url token connection UNIFI API.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/connection_params-class.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Class containing UNIFI API connection parameters — connection_params-class","text":"","code":"# S4 method for class 'connection_params' connection_apihosturl(obj)  # S4 method for class 'connection_params' connection_token(obj)"},{"path":"https://leesulab.github.io/arcMS/reference/connection_params-class.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Class containing UNIFI API connection parameters — connection_params-class","text":"obj connection_params object access.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/connection_params-class.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Class containing UNIFI API connection parameters — connection_params-class","text":"connection_apihosturl returns character object containing connection url. connection_token returns character object containing connection token.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/connection_params-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Class containing UNIFI API connection parameters — connection_params-class","text":"Objects class returned create_connection_params.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/connection_params-class.html","id":"methods-by-generic-","dir":"Reference","previous_headings":"","what":"Methods (by generic)","title":"Class containing UNIFI API connection parameters — connection_params-class","text":"connection_apihosturl(connection_params): Accessor method obtain connection url. connection_token(connection_params): Accessor method obtain connection token.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/connection_params-class.html","id":"slots","dir":"Reference","previous_headings":"","what":"Slots","title":"Class containing UNIFI API connection parameters — connection_params-class","text":"identityurl Contains character URL connection UNIFI identity server. username Contains character user name connection UNIFI identity server (e.g. administrator). password Contains character user password connection UNIFI identity server (e.g. administrator). apihosturl Contains character URL connection UNIFI API server (host). token character token sent back UNIFI API.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/connection_params-class.html","id":"use-the-create-connection-params-to","dir":"Reference","previous_headings":"","what":"Use the create_connection_params to","title":"Class containing UNIFI API connection parameters — connection_params-class","text":"store connection parameters,   using default parameters replacing needed URLs,   username password UNIFI API. request connection   token used functions retrieve data.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/convert_all_samples_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert data from all samples in an Analysis — convert_all_samples_data","title":"Convert data from all samples in an Analysis — convert_all_samples_data","text":"function collects samples data Analysis using collect_one_sample_data() function save disk.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/convert_all_samples_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert data from all samples in an Analysis — convert_all_samples_data","text":"","code":"convert_all_samples_data(   analysis_id,   connection_params = NULL,   format = \"parquet\",   path = NULL,   overwrite = T,   num_spectras = NULL )"},{"path":"https://leesulab.github.io/arcMS/reference/convert_all_samples_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert data from all samples in an Analysis — convert_all_samples_data","text":"analysis_id id analysis connection_params OPTIONAL: Connection parameters object created create_connection_params function. provided, get_connection_params look object global environment format format chosen exported file (Parquet HDF5) path OPTIONAL destination path exported files overwrite OPTIONAL overwrite sample already present disk num_spectras OPTIONAL number spectra collected converted (need convert whole samples, e.g. testing purposes)","code":""},{"path":"https://leesulab.github.io/arcMS/reference/convert_all_samples_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert data from all samples in an Analysis — convert_all_samples_data","text":"dataframe sample saved Parquet HDF5 format folder named Analysis.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/convert_bin_to_ccs.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert bin value to CCS (Collision Cross Section) value — convert_bin_to_ccs","title":"Convert bin value to CCS (Collision Cross Section) value — convert_bin_to_ccs","text":"function converts bin values CCS values given sample. conversion performed limited number detected peaks raw data avoid many requests useless CCS calculations m/z peaks fragments. Peak lists can obtained peak detection, example using DEIMoS Python library. information DEIMoS, see https://deimos.readthedocs.io/en/latest/.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/convert_bin_to_ccs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert bin value to CCS (Collision Cross Section) value — convert_bin_to_ccs","text":"","code":"convert_bin_to_ccs(sample_dataset, connection_params = NULL)"},{"path":"https://leesulab.github.io/arcMS/reference/convert_bin_to_ccs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert bin value to CCS (Collision Cross Section) value — convert_bin_to_ccs","text":"sample_dataset sample_dataset object containing sample data. data include necessary columns: `bin`, `mz`, `rt`. `id` sample present `sample_metadata` slot sample_dataset object. connection_params OPTIONAL: Connection parameters object created create_connection_params function. provided, get_connection_params look object global environment.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/convert_bin_to_ccs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert bin value to CCS (Collision Cross Section) value — convert_bin_to_ccs","text":"sample_dataset object including original data additional column `CCS` containing CCS values.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/convert_one_sample_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert one sample — convert_one_sample_data","title":"Convert one sample — convert_one_sample_data","text":"function collects spectral data sample UNIFI Analysis. First, asynchronous queries performed sample. , data deserialized deserialize_data function. S3 object containing spectral data adapted dataframe outputlist_to_df function. Finally, data saved disk Parquet HDF5 format save_one_sample_data function.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/convert_one_sample_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert one sample — convert_one_sample_data","text":"","code":"convert_one_sample_data(   sample_id,   connection_params = NULL,   format = \"parquet\",   path = NULL,   overwrite = T,   num_spectras = NULL )"},{"path":"https://leesulab.github.io/arcMS/reference/convert_one_sample_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert one sample — convert_one_sample_data","text":"sample_id id sample collected connection_params OPTIONAL: Connection parameters object created create_connection_params function. provided, get_connection_params look object global environment format format chosen exported file (Parquet HDF5) path OPTIONAL destination path exported file overwrite OPTIONAL overwrite sample already present disk num_spectras OPTIONAL Number spectras downloaded (OPTIONAL, whole sample data needed, e.g. testing purposes)","code":""},{"path":"https://leesulab.github.io/arcMS/reference/convert_one_sample_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert one sample — convert_one_sample_data","text":"Datatables sample's spectral data metadata saved Parquet HDF5 format analysis name folder.","code":""},{"path":[]},{"path":"https://leesulab.github.io/arcMS/reference/create_connection_params.html","id":null,"dir":"Reference","previous_headings":"","what":"Create connection parameters — create_connection_params","title":"Create connection parameters — create_connection_params","text":"Create connection parameters","code":""},{"path":"https://leesulab.github.io/arcMS/reference/create_connection_params.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create connection parameters — create_connection_params","text":"","code":"create_connection_params(   identityurl = \"http://localhost:50333/identity/connect/token\",   username = \"administrator\",   password = \"administrator\",   apihosturl = \"http://localhost:50034/unifi/v1\",   install = TRUE )"},{"path":"https://leesulab.github.io/arcMS/reference/create_connection_params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create connection parameters — create_connection_params","text":"identityurl url connect UNIFI API identity server. username username connect UNIFI API identity server. password password connect UNIFI API identity server. apihosturl url connect UNIFI API server (host). install TRUE, install token .Renviron file use future sessions.  Defaults TRUE.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/create_connection_params.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create connection parameters — create_connection_params","text":"list containing parameters needed connection, connection_params object.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/create_connection_params.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create connection parameters — create_connection_params","text":"create_connection_params utility function returns url token UNIFI API connection","code":""},{"path":"https://leesulab.github.io/arcMS/reference/create_sample_dataset.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a sample dataset from a Parquet file created by arcMS — create_sample_dataset","title":"Create a sample dataset from a Parquet file created by arcMS — create_sample_dataset","text":"function creates sample dataset object data imported Parquet file. '","code":""},{"path":"https://leesulab.github.io/arcMS/reference/create_sample_dataset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a sample dataset from a Parquet file created by arcMS — create_sample_dataset","text":"","code":"create_sample_dataset(file, method = \"inram\")"},{"path":"https://leesulab.github.io/arcMS/reference/create_sample_dataset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a sample dataset from a Parquet file created by arcMS — create_sample_dataset","text":"file character file name URI Parquet file. method Whether import data RAM (\"inram\") keep -disk (\"ondisk\")","code":""},{"path":"https://leesulab.github.io/arcMS/reference/create_sample_dataset.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a sample dataset from a Parquet file created by arcMS — create_sample_dataset","text":"sample_dataset object, containing sample data, sample metadata spectrum metadata datatables.","code":""},{"path":[]},{"path":"https://leesulab.github.io/arcMS/reference/deserialize_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Deserialize data — deserialize_data","title":"Deserialize data — deserialize_data","text":"function deserialize protobuf data","code":""},{"path":"https://leesulab.github.io/arcMS/reference/deserialize_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Deserialize data — deserialize_data","text":"","code":"deserialize_data(rg_content)"},{"path":"https://leesulab.github.io/arcMS/reference/deserialize_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Deserialize data — deserialize_data","text":"rg_content $content request octet-stream","code":""},{"path":"https://leesulab.github.io/arcMS/reference/deserialize_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Deserialize data — deserialize_data","text":"S3 object contains spectral data associated spectrum","code":""},{"path":"https://leesulab.github.io/arcMS/reference/explode_spectra.html","id":null,"dir":"Reference","previous_headings":"","what":"Explode Spectra Data — explode_spectra","title":"Explode Spectra Data — explode_spectra","text":"function takes wide format dataframe unnests (explodes) long format. unnested table contains columns rt (retention time), scanid (id scan), mslevel (1 2, .e. low high energy MSe data), mz (m/z values), bin (drift time bin) intensities.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/explode_spectra.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Explode Spectra Data — explode_spectra","text":"","code":"explode_spectra(wide_df)"},{"path":"https://leesulab.github.io/arcMS/reference/explode_spectra.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Explode Spectra Data — explode_spectra","text":"wide_df wide format dataframe columns 'mz', 'intensity', 'scan_size'.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/explode_spectra.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Explode Spectra Data — explode_spectra","text":"long format dataframe exploded spectral data.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/folders_search.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve Folders from UNIFI API — folders_search","title":"Retrieve Folders from UNIFI API — folders_search","text":"function retrieves folder information UNIFI API using provided connection parameters.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/folders_search.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve Folders from UNIFI API — folders_search","text":"","code":"folders_search(connection_params = NULL)"},{"path":"https://leesulab.github.io/arcMS/reference/folders_search.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve Folders from UNIFI API — folders_search","text":"connection_params Connection parameters UNIFI API, including API host URL access token.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/folders_search.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve Folders from UNIFI API — folders_search","text":"data frame containing folder information UNIFI API.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/get_connection_params.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve the connection parameters object — get_connection_params","title":"Retrieve the connection parameters object — get_connection_params","text":"function retrieve connection parameters object global environment, created create_connection_params function","code":""},{"path":"https://leesulab.github.io/arcMS/reference/get_connection_params.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve the connection parameters object — get_connection_params","text":"","code":"get_connection_params(envir = parent.frame())"},{"path":"https://leesulab.github.io/arcMS/reference/get_connection_params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve the connection parameters object — get_connection_params","text":"envir environment look object containing connection parameters","code":""},{"path":"https://leesulab.github.io/arcMS/reference/get_sample_infos.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve Sample Information from UNIFI API with a sample id — get_sample_infos","title":"Retrieve Sample Information from UNIFI API with a sample id — get_sample_infos","text":"function retrieves sample metadata spectrum information UNIFI API specified sample result using provided connection parameters. extracts detailed spectrum information associated given sample result identifier. function returns two dataframes containing sample information spectrum informationn, two formatted JSON strings data.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/get_sample_infos.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve Sample Information from UNIFI API with a sample id — get_sample_infos","text":"","code":"get_sample_infos(sample_id, connection_params = NULL)"},{"path":"https://leesulab.github.io/arcMS/reference/get_sample_infos.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve Sample Information from UNIFI API with a sample id — get_sample_infos","text":"sample_id identifier sample result spectrum information retrieved. connection_params OPTIONAL: Connection parameters object created create_connection_params function. provided, get_connection_params look object global environment","code":""},{"path":"https://leesulab.github.io/arcMS/reference/get_sample_infos.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve Sample Information from UNIFI API with a sample id — get_sample_infos","text":"sample_infos object, consisting list containing two elements: dataframe detailed sample information UNIFI API, formatted JSON string sample information. Example usage: con_params <- create_connection_params() results <- get_sample_infos(sample_result_id, con_params)","code":""},{"path":"https://leesulab.github.io/arcMS/reference/get_samples_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve the list of Samples Results from an Analysis in UNIFI API — get_samples_list","title":"Retrieve the list of Samples Results from an Analysis in UNIFI API — get_samples_list","text":"function connects UNIFI Analysis gets list samples. returns dataframe sample names IDs, along analysis name.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/get_samples_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve the list of Samples Results from an Analysis in UNIFI API — get_samples_list","text":"","code":"get_samples_list(analysis_id, connection_params = NULL)"},{"path":"https://leesulab.github.io/arcMS/reference/get_samples_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve the list of Samples Results from an Analysis in UNIFI API — get_samples_list","text":"analysis_id identifier Analysis connection_params OPTIONAL: Connection parameters object created create_connection_params function. provided, get_connection_params look object global environment","code":""},{"path":"https://leesulab.github.io/arcMS/reference/get_samples_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve the list of Samples Results from an Analysis in UNIFI API — get_samples_list","text":"dataframe wih sample names IDs, along analysis name sample metadata.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/get_unifi_api_token.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve the API token in the environment variable — get_unifi_api_token","title":"Retrieve the API token in the environment variable — get_unifi_api_token","text":"function retrieve UNIFI API token OS environment","code":""},{"path":"https://leesulab.github.io/arcMS/reference/get_unifi_api_token.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve the API token in the environment variable — get_unifi_api_token","text":"","code":"get_unifi_api_token()"},{"path":"https://leesulab.github.io/arcMS/reference/outputlist_to_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Transform deserialized data to a dataframe — outputlist_to_df","title":"Transform deserialized data to a dataframe — outputlist_to_df","text":"function adapts data S3 format obtained `deserialize_data()` function dataframe.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/outputlist_to_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transform deserialized data to a dataframe — outputlist_to_df","text":"","code":"outputlist_to_df(outputlist)"},{"path":"https://leesulab.github.io/arcMS/reference/outputlist_to_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transform deserialized data to a dataframe — outputlist_to_df","text":"outputlist Deserialized data S3 format obtained deserialized_data() function","code":""},{"path":"https://leesulab.github.io/arcMS/reference/outputlist_to_df.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transform deserialized data to a dataframe — outputlist_to_df","text":"dataframe containing spectral data associated spectra.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/run_app.html","id":null,"dir":"Reference","previous_headings":"","what":"Run Shiny application to use the conversion package — run_app","title":"Run Shiny application to use the conversion package — run_app","text":"function launches Shiny app. app can used connect UNIFI API, navigate folders analyses available UNIFI, select samples analysis convert, run conversion. destination folder converted files format (Parquet HDF5) can chosen.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/run_app.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run Shiny application to use the conversion package — run_app","text":"","code":"run_app()"},{"path":"https://leesulab.github.io/arcMS/reference/sample_dataset-class.html","id":null,"dir":"Reference","previous_headings":"","what":"Class containing a sample data and metadata — sample_dataset-class","title":"Class containing a sample data and metadata — sample_dataset-class","text":"Contains sample data (data.table RAM pointer Parquet file), metadata spectrum metadata table json formats.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/sample_dataset-class.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Class containing a sample data and metadata — sample_dataset-class","text":"","code":"# S4 method for class 'sample_dataset' get_sample_data(obj)"},{"path":"https://leesulab.github.io/arcMS/reference/sample_dataset-class.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Class containing a sample data and metadata — sample_dataset-class","text":"obj sample_dataset object access.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/sample_dataset-class.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Class containing a sample data and metadata — sample_dataset-class","text":"get_sample_data returns data.table object containing sample data.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/sample_dataset-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Class containing a sample data and metadata — sample_dataset-class","text":"Objects class returned collect_one_sample_data create_sample_dataset.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/sample_dataset-class.html","id":"methods-by-generic-","dir":"Reference","previous_headings":"","what":"Methods (by generic)","title":"Class containing a sample data and metadata — sample_dataset-class","text":"get_sample_data(sample_dataset): Accessor method obtain sample_data table.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/sample_dataset-class.html","id":"slots","dir":"Reference","previous_headings":"","what":"Slots","title":"Class containing a sample data and metadata — sample_dataset-class","text":"sample_data Contains datatable sample data, Arrow Dataset R6 object pointing Parquet file data. sample_metadata Contains datatable sample metadata. spectrum_metadata Contains datatable spectrum metadata. sample_metadata_json Contains character sample metadata. spectrum_metadata_json Contains character spectrum metadata.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/sample_dataset-class.html","id":"use-the-collect-one-sample-data-to","dir":"Reference","previous_headings":"","what":"Use the collect_one_sample_data to","title":"Class containing a sample data and metadata — sample_dataset-class","text":"store sample data, metadata spectrum metadata, table json formats.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/sample_infos-class.html","id":null,"dir":"Reference","previous_headings":"","what":"Class containing a sample's information — sample_infos-class","title":"Class containing a sample's information — sample_infos-class","text":"Contains sample metadata spectrum metadata table json formats.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/sample_infos-class.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Class containing a sample's information — sample_infos-class","text":"","code":"# S4 method for class 'sample_infos' get_sample_metadata(obj)  # S4 method for class 'sample_infos' get_sample_name(obj)  # S4 method for class 'sample_infos' get_sample_id(obj)  # S4 method for class 'sample_infos' get_analysis_name(obj)  # S4 method for class 'sample_infos' get_sample_metadata_json(obj)  # S4 method for class 'sample_infos' get_spectrum_metadata(obj)  # S4 method for class 'sample_infos' get_spectrum_metadata_json(obj)  # S4 method for class 'sample_infos' add_sample_id(obj, id)"},{"path":"https://leesulab.github.io/arcMS/reference/sample_infos-class.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Class containing a sample's information — sample_infos-class","text":"obj sample_infos object access. id identifier sample result spectrum information retrieved.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/sample_infos-class.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Class containing a sample's information — sample_infos-class","text":"get_sample_metadata returns data.table object containing sample metadata. get_sample_name returns character object containing sample name. get_sample_id returns character object containing sample id. get_analysis_name returns character object containing analysis name. get_sample_metadata_json returns json character object containing sample metadata. get_spectrum_metadata returns data.table object containing spectrum metadata sample. get_spectrum_metadata_json returns json character object containing spectrum metadata sample. add_sample_id returns character object containing sample id.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/sample_infos-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Class containing a sample's information — sample_infos-class","text":"Objects class returned get_sample_infos.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/sample_infos-class.html","id":"methods-by-generic-","dir":"Reference","previous_headings":"","what":"Methods (by generic)","title":"Class containing a sample's information — sample_infos-class","text":"get_sample_metadata(sample_infos): Accessor method obtain sample_infos table. get_sample_name(sample_infos): Accessor method obtain sample name. get_sample_id(sample_infos): Accessor method obtain sample id. get_analysis_name(sample_infos): Accessor method obtain analysis name. get_sample_metadata_json(sample_infos): Accessor method obtain sample metadata json format. get_spectrum_metadata(sample_infos): Accessor method obtain spectrum_metadata table. get_spectrum_metadata_json(sample_infos): Accessor method obtain spectrum metadata json format. add_sample_id(sample_infos): Method add sample ID sample_infos object.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/sample_infos-class.html","id":"slots","dir":"Reference","previous_headings":"","what":"Slots","title":"Class containing a sample's information — sample_infos-class","text":"sample_metadata Contains datatable sample metadata. spectrum_metadata Contains datatable spectrum metadata. sample_metadata_json Contains character sample metadata. spectrum_metadata_json Contains character spectrum metadata.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/sample_infos-class.html","id":"use-the-get-sample-infos-to","dir":"Reference","previous_headings":"","what":"Use the get_sample_infos to","title":"Class containing a sample's information — sample_infos-class","text":"store sample metadata spectrum metadata, table json formats.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/save_one_sample_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Save collected data from one sample — save_one_sample_data","title":"Save collected data from one sample — save_one_sample_data","text":"function saves data collected one sample collect_one_sample_data function. Datatables spectra metadata saved either two Parquet files one HDF5 file.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/save_one_sample_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save collected data from one sample — save_one_sample_data","text":"","code":"save_one_sample_data(   sample_dataset,   sample_name = NULL,   analysis_name = NULL,   path = NULL,   format = \"parquet\" )"},{"path":"https://leesulab.github.io/arcMS/reference/save_one_sample_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save collected data from one sample — save_one_sample_data","text":"sample_dataset Collected data sample, stored sample_dataset object sample_name OPTIONAL sample name (used naming saved file) analysis_name OPTIONAL name Analysis (used naming folder) path OPTIONAL destination path exported file format format chosen exported file (parquet hdf5)","code":""},{"path":"https://leesulab.github.io/arcMS/reference/save_one_sample_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Save collected data from one sample — save_one_sample_data","text":"Datatables sample's spectral data metadata saved Parquet HDF5 format analysis name folder.","code":""},{"path":[]},{"path":"https://leesulab.github.io/arcMS/reference/store_unifi_api_token.html","id":null,"dir":"Reference","previous_headings":"","what":"Save the API token in the .Renviron file for repeated use — store_unifi_api_token","title":"Save the API token in the .Renviron file for repeated use — store_unifi_api_token","text":"function add UNIFI API token .Renviron file can called securely without stored code. installed key, can called time typing Sys.getenv(\"UNIFI_API_TOKEN\") can used package functions simply typing UNIFI_API_TOKEN .Renviron file, function create . already .Renviron file, function append key existing file, making backup original file disaster recovery purposes. Function obtained adapted tidycensus package","code":""},{"path":"https://leesulab.github.io/arcMS/reference/store_unifi_api_token.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save the API token in the .Renviron file for repeated use — store_unifi_api_token","text":"","code":"store_unifi_api_token(token, overwrite = FALSE, install = FALSE)"},{"path":"https://leesulab.github.io/arcMS/reference/store_unifi_api_token.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save the API token in the .Renviron file for repeated use — store_unifi_api_token","text":"token API token retrieved UNIFI formated quotes. overwrite set TRUE, overwrite existing UNIFI_API_TOKEN already .Renviron file. install TRUE, install token .Renviron file use future sessions.  Defaults FALSE.","code":""},{"path":"https://leesulab.github.io/arcMS/reference/store_unifi_api_token.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Save the API token in the .Renviron file for repeated use — store_unifi_api_token","text":"","code":"if (FALSE) { # \\dontrun{ unifi_api_token(\"111111abc\", install = TRUE) # First time, reload your environment so you can use the key without restarting R. readRenviron(\"~/.Renviron\") # You can check it with: Sys.getenv(\"UNIFI_API_TOKEN\") } # }  if (FALSE) { # \\dontrun{ # If you need to overwrite an existing key: unifi_api_token(\"111111abc\", overwrite = TRUE, install = TRUE) # First time, relead your environment so you can use the key without restarting R. readRenviron(\"~/.Renviron\") # You can check it with: Sys.getenv(\"UNIFI_API_TOKEN\") } # }"},{"path":[]},{"path":"https://leesulab.github.io/arcMS/news/index.html","id":"changes-1-1-0","dir":"Changelog","previous_headings":"","what":"Changes","title":"arcMS 1.1.0","text":"Compatibility waters_connect UNIFI Adding vignette describe configure API register client app","code":""},{"path":[]},{"path":"https://leesulab.github.io/arcMS/news/index.html","id":"changes-1-0-0","dir":"Changelog","previous_headings":"","what":"Changes","title":"arcMS 1.0.0","text":"Shiny app easy use need connection parameters function (looking existing object environment)","code":""},{"path":[]},{"path":"https://leesulab.github.io/arcMS/news/index.html","id":"changes-0-3-0","dir":"Changelog","previous_headings":"","what":"Changes","title":"arcMS 0.3.0","text":"Creation sample_infos class store sample metadata spectrum metadata. Creation sample_dataset class store data metadata.","code":""},{"path":[]},{"path":"https://leesulab.github.io/arcMS/news/index.html","id":"changes-0-2-0","dir":"Changelog","previous_headings":"","what":"Changes","title":"arcMS 0.2.0","text":"simplified arguments collect convert functions (sample_id needed, parameters needed - analysis name, sample name - taken API request). adding separate function get sample information (get_sample_infos) save samplemetadata. Two metadata (samplemetadata spectrummetadata) different schemas/number lines columns. parquet: metadata json file containing samplemetadata spectrummetadata. HDF5: two separate datasets file.","code":""},{"path":"https://leesulab.github.io/arcMS/news/index.html","id":"arcms-010","dir":"Changelog","previous_headings":"","what":"arcMS 0.1.0","title":"arcMS 0.1.0","text":"Initial github upload.","code":""}]
